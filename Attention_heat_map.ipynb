{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Attention_heat_map.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UqiYZcDHeRw04ShKjxGj6sUodwSjvTc5","authorship_tag":"ABX9TyPSFRlxfSvSb6FCfv9BJDh+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9S23JN3ODy8n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608070569178,"user_tz":480,"elapsed":19354,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"a431d3e2-dc27-42c2-e894-b59110af2b71"},"source":["# Mount Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U7zom4EF5kqR","executionInfo":{"status":"ok","timestamp":1608070573169,"user_tz":480,"elapsed":3395,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# import libraries\n","import csv\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from torchtext.data.utils import get_tokenizer\n","from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqHscPRO7ka3","executionInfo":{"status":"ok","timestamp":1608070573170,"user_tz":480,"elapsed":1817,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["class Dataset():\n","  def __init__(self, filename):\n","      self.sentences, self.score = self.read_data(filename)\n","  def read_data(self, filename):\n","      sentences = []\n","      scores = []\n","\n","      current_sentence = []\n","\n","      with open(filename, encoding='utf8') as f:\n","        csvreader = csv.reader(f, delimiter=',')\n","        for row in csvreader:\n","          comment_num = row[0]\n","          comment = tokenizer(row[1])\n","          label = row[2]\n","          sentences.append(comment)\n","          scores.append(label)\n","      \n","      return sentences,scores"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNih_L0t_3wo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608070802549,"user_tz":480,"elapsed":1240,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"b9285cfb-9103-467c-e088-b9c4d692a5f8"},"source":["sentences = []\n","scores = []\n","tokenizer = get_tokenizer(\"spacy\")\n","\n","# open data\n","with open('/content/drive/My Drive/NLP_259/final_labels.csv', encoding='utf8') as f:\n","  csvreader = csv.reader(f, delimiter=',')\n","  for row in csvreader:\n","    comment = tokenizer(row[1])\n","    label = row[2]\n","    sentences.append(comment)\n","    scores.append(label)\n","\n","# Get ride of header \n","sentences = sentences[1:]\n","scores = scores[1:]\n","\n","# Make float\n","scores_new = []\n","for item in scores:\n","    scores_new.append(float(item))\n","\n","print(\"Size of sentences and scores:\", len(sentences),len(scores_new))\n","print (\"Example: \", sentences[0][:10])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Size of sentences and scores: 120 120\n","Example:  ['I', 'was', 'in', 'the', 'Navy', ',', 'and', 'I', 'used', 'to']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XvBIhRJ392Xh","executionInfo":{"status":"ok","timestamp":1608070810217,"user_tz":480,"elapsed":578,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["def read_embeddings(filename, vocab_size=10000):\n","  \"\"\"\n","  Utility function, loads in the `vocab_size` most common embeddings from `filename`\n","  \n","  Arguments:\n","  - filename:     path to file\n","                  automatically infers correct embedding dimension from filename\n","  - vocab_size:   maximum number of embeddings to load\n","\n","  Returns \n","  - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n","  - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n","  \"\"\"\n","\n","  # get the embedding size from the first embedding\n","  with open(filename, encoding=\"utf-8\") as file:\n","    word_embedding_dim = len(file.readline().split(\" \")) - 1\n","\n","  vocab = {}\n","\n","  embeddings = np.zeros((vocab_size, word_embedding_dim))\n","\n","  with open(filename, encoding=\"utf-8\") as file:\n","    for idx, line in enumerate(file):\n","\n","      if idx + 2 >= vocab_size:\n","        break\n","\n","      cols = line.rstrip().split(\" \")\n","      val = np.array(cols[1:])\n","      word = cols[0]\n","      embeddings[idx + 2] = val\n","      vocab[word] = idx + 2\n","  \n","  # a FloatTensor is a multidimensional matrix\n","  # that contains 32-bit floats in every entry\n","  # https://pytorch.org/docs/stable/tensors.html\n","  return torch.FloatTensor(embeddings), vocab"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXUXXYltFDzC","executionInfo":{"status":"ok","timestamp":1608071138017,"user_tz":480,"elapsed":1860,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# this loads the 10,000 most common word 50-dimensional embeddings\n","embedding_file = '/content/drive/My Drive/NLP_259/glove.6B.50d.txt'\n","vocab_size = 10000\n","embeddings, vocab = read_embeddings(embedding_file, vocab_size)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"teag5tqTFT44"},"source":["# # This batching Process\n","# batch_size = 10\n","# PAD_INDEX = 0             # reserved for padding words\n","# UNKNOWN_INDEX = 1         # reserved for unknown words\n","\n","# np.random.seed(159) # don't change this, for reproducibility\n","# shuffle = np.random.permutation(range(len(sentences)))\n","\n","# #grabs the relevant data from the random permutation\n","# shuffled_sentences = [sentences[i] for i in shuffle]\n","# shuffled_scores = [scores_new[i] for i in shuffle]\n","\n","# # batched length, batched sentences, batched y-label\n","# batched_lengths, batched_sent_idxs, batched_scores = [], [], []\n","\n","# #creates batches\n","# N = len(shuffled_sentences)\n","# if N % batch_size == 0:\n","#   num_batches = N // batch_size\n","# else:\n","#   num_batches = N // batch_size + 1\n","\n","# # loop through batches\n","# for b in range(num_batches):\n","#   start = b * batch_size # Batch starting splitting index \n","#   stop = min((b+1) * batch_size, len(shuffled_sentences)) # batch ending index\n","  \n","#   # At the batch level\n","#   #calculates the max lengths of response and past turn sequences for this batch\n","#   # this is for padding purposes\n","#   max_seq_len = max([len(s) for s in shuffled_sentences[start:stop]])\n","#   sent_idx = np.zeros((stop-start, max_seq_len)) # matrix to capture all sentences index\n","#   sent_lengths = np.zeros((stop-start))\n","#   y_labels = np.zeros((stop-start))\n","\n","#   # Within the batch\n","#   for i in range(start, stop):\n","#     #gathers the corresponding data\n","#     current_sent = shuffled_sentences[i]\n","#     #this captures the lengths \n","#     sent_lengths[i - start] = len(current_sent)\n","#     #y-label\n","#     y_labels[i - start] = shuffled_scores[i]\n","\n","#     #this gets the vocabulary IDs for each word in the past_turn and response\n","#     #UNKNOWN_INDEX is used if the word is out of vocabulary\n","#     for j in range(len(current_sent)):\n","#       if current_sent[j].lower() in vocab:\n","#         sent_idx[i - start][j] = vocab[current_sent[j].lower()]\n","#       else:\n","#         sent_idx[i - start][j] = UNKNOWN_INDEX      \n","\n","\n","#   batched_lengths.append(sent_lengths)\n","#   batched_sent_idxs.append(sent_idx)\n","#   batched_scores.append(y_labels)\n","\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IINshem_TmCn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608071143297,"user_tz":480,"elapsed":517,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"3a7c879f-f889-4fb0-fd9c-96618d3c5a07"},"source":["PAD_INDEX = 0             # reserved for padding words\n","UNKNOWN_INDEX = 1         # reserved for unknown words\n","\n","max_seq_len = max([len(s) for s in sentences])\n","sent_idxs = np.zeros((len(sentences), max_seq_len))\n","sent_lengths = np.zeros((len(sentences)))\n","\n","for i in range(len(sentences)):\n","  current_sent = sentences[i]\n","  sent_lengths[i] = len(current_sent)\n","  for j in range(len(current_sent)):\n","    if current_sent[j].lower() in vocab:\n","      sent_idxs[i][j] = vocab[current_sent[j].lower()]\n","    else:\n","      sent_idxs[i][j] = UNKNOWN_INDEX  \n","\n","len(sent_idxs)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["120"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"4TqhGSOgwxXm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608071145834,"user_tz":480,"elapsed":494,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"b214f316-ab99-408e-dea1-0efd4e29533f"},"source":["# Sanity Check\n","sent_idxs[0]\n","sent_lengths"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 72.,  79.,  56.,  13.,  35.,  35.,  23.,  89.,  58.,  50.,  19.,\n","        26.,  63.,  45.,  93.,   5.,  25.,  21., 371., 143., 177., 153.,\n","        33.,  17.,  44.,  16.,  13., 107.,  55.,  92.,  16.,  40.,  83.,\n","        12.,  64., 100.,  21.,   8., 114.,  75.,  74.,   8.,  21., 242.,\n","        20., 185.,  28., 115.,  66.,  16.,  15.,  38.,  70.,  20.,  24.,\n","        13., 146., 149.,  82.,  96., 229.,  40.,  64.,  19.,  58.,   9.,\n","       203.,  83., 147.,  59.,  45.,  37.,  90.,  61.,  71.,  38.,  48.,\n","         7., 142.,  21.,  13.,  16.,  53.,  48.,  42.,  30.,  38.,  45.,\n","        74.,  37.,  31.,  11.,  19.,   7.,  13.,  27.,  95.,  32., 108.,\n","        57.,  25.,  67., 265.,  22.,   4.,  20.,  16., 191.,  26.,  15.,\n","       248., 630.,  63.,  13.,  58.,  86.,  19.,  44., 198.,  64.])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"AQdPsqDQJOwv","executionInfo":{"status":"ok","timestamp":1608071154684,"user_tz":480,"elapsed":483,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# Create Attention layer\n","class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        \n","        self.supports_masking = True\n","\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        \n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.kaiming_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","        \n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(step_dim))\n","        \n","    def forward(self, x, mask=None):\n","        feature_dim = self.feature_dim \n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","        \n","        if self.bias:\n","            eij = eij + self.b\n","            \n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","        \n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n","        \n","        weighted_input = x * torch.unsqueeze(a, -1)\n","\n","        return torch.sum(weighted_input, 1) , a"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6xq0tClHJG5","executionInfo":{"status":"ok","timestamp":1608071157323,"user_tz":480,"elapsed":562,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# Make one layer LSTM with attention layer\n","\n","class Attention_Net(nn.Module):\n","    def __init__(self,embeddings, maxlen):\n","        super(Attention_Net, self).__init__()\n","        embed_size = embeddings.shape[1]\n","        self.hidden_size = 64\n","        self.trained_att_weights = torch.zeros(maxlen)\n","        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=False)\n","        # self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        # self.embedding.weight.requires_grad = False\n","        # self.embedding_dropout = nn.Dropout2d(0.1)\n","\n","        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=False)\n","        # self.lstm2 = nn.GRU(128*2, 64, bidirectional=True, batch_first=True)\n","\n","        self.attention_layer = Attention(self.hidden_size * 2, maxlen)\n","        \n","        self.linear = nn.Linear(self.hidden_size * 2 , 32)\n","        self.relu = nn.ReLU()\n","        self.out = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        h_embedding = self.embedding(x)\n","        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n","        h_lstm, _ = self.lstm(h_embedding)\n","        # h_lstm, _ = self.lstm2(h_lstm)\n","        h_lstm_atten, _ = self.attention_layer(h_lstm)\n","        conc = self.relu(self.linear(h_lstm_atten))\n","        out = self.out(conc)\n","        return out\n","    \n","    def get_attentweights_with_x(self,x):\n","        h_embedding = self.embedding(x)\n","        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n","        h_lstm, _ = self.lstm(h_embedding)\n","        # h_lstm, _ = self.lstm2(h_lstm)\n","        _, trained_weight = self.attention_layer(h_lstm)\n","        return trained_weight"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmykWsM2LAPG","executionInfo":{"status":"ok","timestamp":1608071161526,"user_tz":480,"elapsed":491,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# Parameter for training\n","MAX_LENGTH = int(max(sent_lengths))\n","model = Attention_Net(embeddings, MAX_LENGTH)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2C_I9mfLiSI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608071164154,"user_tz":480,"elapsed":1616,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"6321afd8-5939-4309-d0f4-89f021cdebeb"},"source":["# Forward Prop\n","forward_test = torch.LongTensor(sent_idxs)\n","forward_test.shape\n","model.forward(forward_test)[:10]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0966],\n","        [0.0975],\n","        [0.0980],\n","        [0.0985],\n","        [0.0987],\n","        [0.0988],\n","        [0.0983],\n","        [0.0984],\n","        [0.0984],\n","        [0.0980]], grad_fn=<SliceBackward>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"4KTZ0QI-O1FA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608071286713,"user_tz":480,"elapsed":120230,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"d0d68d99-727a-4d74-e63f-ddd365587db2"},"source":["# Training\n","LEARNING_RATE = 1e-3\n","num_epochs = 100\n","# let's train the model \n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# loss_function = nn.CrossEntropyLoss(ignore_index = 1)\n","loss_function = nn.L1Loss(reduction='sum')\n","\n","print(\"**** TRAINING *****\")\n","for i in range(num_epochs):\n","  model.train()\n","  total_loss = 0\n","  # compute the logits\n","  logits = model.forward(torch.LongTensor(sent_idxs)).view(-1)\n","  # move labels to GPU memory\n","  labels = torch.LongTensor(scores_new)\n","  # print(logits.shape)\n","  # print(labels.shape)\n","  loss = loss_function(logits, labels)\n","  #loss = loss_function(logits, labels)\n","  total_loss += loss\n","  # propagate gradients backward\n","  loss.backward()\n","  optimizer.step()\n","  # set model gradients to zero before performing next forward pass\n","  model.zero_grad()\n","\n","  if (i + 1) % 5 == 0:\n","    print(\"Epoch {} | Loss: {}\".format(i + 1, total_loss))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["**** TRAINING *****\n","Epoch 5 | Loss: 46.73244857788086\n","Epoch 10 | Loss: 46.43602752685547\n","Epoch 15 | Loss: 46.158573150634766\n","Epoch 20 | Loss: 46.16778564453125\n","Epoch 25 | Loss: 46.089176177978516\n","Epoch 30 | Loss: 46.0499153137207\n","Epoch 35 | Loss: 46.027503967285156\n","Epoch 40 | Loss: 46.00292205810547\n","Epoch 45 | Loss: 45.99393844604492\n","Epoch 50 | Loss: 45.980979919433594\n","Epoch 55 | Loss: 45.96519470214844\n","Epoch 60 | Loss: 45.94905090332031\n","Epoch 65 | Loss: 45.95695495605469\n","Epoch 70 | Loss: 45.96592330932617\n","Epoch 75 | Loss: 45.922019958496094\n","Epoch 80 | Loss: 45.918663024902344\n","Epoch 85 | Loss: 45.88459014892578\n","Epoch 90 | Loss: 45.84555435180664\n","Epoch 95 | Loss: 45.81193923950195\n","Epoch 100 | Loss: 45.78041458129883\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o6639H7NIwWx","executionInfo":{"status":"ok","timestamp":1608071361126,"user_tz":480,"elapsed":982,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# Sanity check on the attention weights\n","forward_test = torch.LongTensor(sent_idxs)\n","wd_weights = model.get_attentweights_with_x(forward_test)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iS2UE7MIyDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608071363684,"user_tz":480,"elapsed":841,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"7d0b3a37-9b18-4bc9-cfe0-48aebfc7bea3"},"source":["wd_weights[0][0:30]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0014, 0.0014, 0.0014, 0.0014, 0.0017, 0.0014, 0.0014, 0.0014, 0.0014,\n","        0.0014, 0.0014, 0.0014, 0.0014, 0.0016, 0.0015, 0.0014, 0.0014, 0.0014,\n","        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n","        0.0014, 0.0014, 0.0014], grad_fn=<SliceBackward>)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"ZHb_jetrLean","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1588131513504,"user_tz":420,"elapsed":3054,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}},"outputId":"68a2a6cb-1e1f-4db5-c220-1d90c1bbe3bf"},"source":["# Credit to Text-Attention-Heatmap-Visualization project by Jie Yang\n","# !git clone https://github.com/jiesutd/Text-Attention-Heatmap-Visualization"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Text-Attention-Heatmap-Visualization'...\n","remote: Enumerating objects: 40, done.\u001b[K\n","remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n","Unpacking objects: 100% (40/40), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3LlPSjrICz9U","executionInfo":{"status":"ok","timestamp":1608071372161,"user_tz":480,"elapsed":579,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["# -*- coding: utf-8 -*-\n","# @Author: Jie Yang\n","# @Date:   2019-03-29 16:10:23\n","# @Last Modified by:   Jie Yang,     Contact: jieynlp@gmail.com\n","# @Last Modified time: 2019-04-12 09:56:12\n","\n","\n","## convert the text/attention list to latex code, which will further generates the text heatmap based on attention weights.\n","import numpy as np\n","\n","latex_special_token = [\"!@#$%^&*()\"]\n","\n","def generate(text_list, attention_list, latex_file, color='red', rescale_value = False):\n","\tassert(len(text_list) == len(attention_list))\n","\tif rescale_value:\n","\t\tattention_list = rescale(attention_list)\n","\tword_num = len(text_list)\n","\ttext_list = clean_word(text_list)\n","\twith open(latex_file,'w') as f:\n","\t\tf.write(r'''\\documentclass[varwidth]{standalone}\n","\\special{papersize=210mm,297mm}\n","\\usepackage{color}\n","\\usepackage{tcolorbox}\n","\\usepackage{CJK}\n","\\usepackage{adjustbox}\n","\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n","\\begin{document}\n","\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n","\t\tstring = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n","\t\tfor idx in range(word_num):\n","\t\t\tstring += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n","\t\tstring += \"\\n}}}\"\n","\t\tf.write(string+'\\n')\n","\t\tf.write(r'''\\end{CJK*}\n","\\end{document}''')\n","\n","def rescale(input_list):\n","\tthe_array = np.asarray(input_list)\n","\tthe_max = np.max(the_array)\n","\tthe_min = np.min(the_array)\n","\trescale = (the_array - the_min)/(the_max-the_min)*100\n","\treturn rescale.tolist()\n","\n","\n","def clean_word(word_list):\n","\tnew_word_list = []\n","\tfor word in word_list:\n","\t\tfor latex_sensitive in [\"\\\\\", \"%\", \"&\", \"^\", \"#\", \"_\",  \"{\", \"}\"]:\n","\t\t\tif latex_sensitive in word:\n","\t\t\t\tword = word.replace(latex_sensitive, '\\\\'+latex_sensitive)\n","\t\tnew_word_list.append(word)\n","\treturn new_word_list\n","\n","\n","if __name__ == '__main__':\n","\t## This is a demo:\n","\n","\tsent = '''the USS Ronald Reagan - an aircraft carrier docked in Japan - during his tour of the region, vowing to \"defeat any attack and meet any use of conventional or nuclear weapons with an overwhelming and effective American response\".\n","North Korea and the US have ratcheted up tensions in recent weeks and the movement of the strike group had raised the question of a pre-emptive strike by the US.\n","On Wednesday, Mr Pence described the country as the \"most dangerous and urgent threat to peace and security\" in the Asia-Pacific.'''\n","\tsent = '''我 回忆 起 我 曾经 在 大学 年代 ， 我们 经常 喜欢 玩 “ Hawaii guitar ” 。 说起 Guitar ， 我 想起 了 西游记 里 的 琵琶精 。\n","\t今年 下半年 ， 中 美 合拍 的 西游记 即将 正式 开机 ， 我 继续 扮演 美猴王 孙悟空 ， 我 会 用 美猴王 艺术 形象 努力 创造 一 个 正能量 的 形象 ， 文 体 两 开花 ， 弘扬 中华 文化 ， 希望 大家 能 多多 关注 。'''\n","\twords = sent.split()\n","\tword_num = len(words)\n","\tattention = [(x+1.)/word_num*100 for x in range(word_num)]\n","\timport random\n","\trandom.seed(42)\n","\trandom.shuffle(attention)\n","\tcolor = 'red'\n","\tgenerate(words, attention, \"sample.tex\", color)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ks06I5zELJ4","executionInfo":{"status":"ok","timestamp":1608071375970,"user_tz":480,"elapsed":584,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["sent_1 = sentences[0]\n","attention_1 = wd_weights[0][:72]\n","attention_1 = [float(i) * 10000 for i in attention_1]\n","generate(sent_1, attention_1, \"sent_1_v4.tex\", 'blue')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"18aUJNJmIlo-","executionInfo":{"status":"ok","timestamp":1608071393991,"user_tz":480,"elapsed":487,"user":{"displayName":"Hongyang Zheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9mbTQtWKTIVMHL6PAk9Y2bJ4hfirLYt13NpHJ=s64","userId":"09588730451776318951"}}},"source":["sent_83 = sentences[83]\n","attention_83 = wd_weights[0][:48]\n","attention_83 = [float(i) * 10000 for i in attention_83]\n","generate(sent_83, attention_83, \"sent_83.tex\", color)"],"execution_count":22,"outputs":[]}]}